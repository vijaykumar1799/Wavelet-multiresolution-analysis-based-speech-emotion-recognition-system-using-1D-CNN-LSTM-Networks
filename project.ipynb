{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "audio filename format modality: channel-emotion-intensity-statement-repetition-actor.wav\n",
    "- Modality -> 01=audio-video, 02=video, 03-audio\n",
    "- Channel -> 01=speech, 02=song\n",
    "- Emotion -> 01=neutral, 02=calm, 03=happy, 04=sad, 05=Angry, 06=Fearful, 07=Disgust, 08=Surprised\n",
    "- Intensity -> 01=Normal, 02=Strong\n",
    "- Statement -> 01=Kids are talking by the door, 02=Dogs are sitting by the door\n",
    "- Repetition -> 01=first repetition, 02=second repetition\n",
    "- Actor -> 01=first actor, ..., 24=twenty-fourth actor\n",
    "\n",
    "The only information needed is emotion label as other data can be disregarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pywt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "from random import seed, random, randint, sample\n",
    "from scipy.signal import hilbert, chirp\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440 Audio files fetched...\n",
      "\n",
      "neutral -> 96 samples.\n",
      "calm -> 192 samples.\n",
      "happy -> 192 samples.\n",
      "sad -> 192 samples.\n",
      "angry -> 192 samples.\n",
      "fearful -> 192 samples.\n",
      "disgust -> 192 samples.\n",
      "surprised -> 192 samples.\n"
     ]
    }
   ],
   "source": [
    "# using speech data\n",
    "speech_folder_name = './Audio_Speech_Actors_01-24/'\n",
    "actors_folder_name = [os.path.join(speech_folder_name, actor) for actor in os.listdir(speech_folder_name)]\n",
    "audio_files_path = [os.path.join(actor_num, file) for actor_num in actors_folder_name for file in os.listdir(actor_num)]\n",
    "data = np.array([[file_path, int(file_path.split('\\\\')[-1].split('-')[2])-1] for file_path in audio_files_path])\n",
    "\n",
    "labels = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']\n",
    "print(f\"{len(audio_files_path)} Audio files fetched...\\n\")\n",
    "labels_idx, count = np.unique(data[:, -1], return_counts=True)\n",
    "for i in range(len(count)):\n",
    "    print(f\"{labels[int(labels_idx[i])]} -> {count[i]} samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_awgn(audio):\n",
    "    snr_db = np.random.uniform(15, 30)\n",
    "    noise_std = np.sqrt(np.var(audio) / (10 ** (snr_db / 10)))\n",
    "    gaussian_noise = np.random.normal(0, noise_std, len(audio))\n",
    "    return audio + gaussian_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(audio):\n",
    "    trimmed, idx = librosa.effects.trim(audio)\n",
    "    norm_seq = (trimmed - np.mean(trimmed)) / np.std(trimmed)\n",
    "    noisy = add_awgn(norm_seq)\n",
    "\n",
    "    return norm_seq, noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wavelet_features(audio, label):\n",
    "    wavelet = 'morl'\n",
    "    sr = 16000\n",
    "    widths = np.arange(1, 256)\n",
    "    #print(f\"Scales using: {widths}\")\n",
    "\n",
    "    dt = 1/sr\n",
    "    frequencies = pywt.scale2frequency(wavelet=wavelet, scale=widths) / dt\n",
    "    #print(f\"Frequencies associated with the scales: {frequencies}\")\n",
    "\n",
    "    #creating filter to select frequencies between 20Hz and 5Khz - this is where most speech lies\n",
    "    upper = [x for x in range(len(widths)) if frequencies[x] > 2000][-1]\n",
    "    lower = [x for x in range(len(widths)) if frequencies[x] < 100][0]\n",
    "\n",
    "    widths = widths[upper:lower]\n",
    "\n",
    "    #computing wavelet transform \n",
    "    wavelet_coefs, freqs = pywt.cwt(audio, widths, wavelet=wavelet, sampling_period=dt)\n",
    "    #print(f\"shape of wavelet transform: {wavelet_coefs.shape}\")\n",
    "\n",
    "    # Fixed Segment Generation\n",
    "    start = 0\n",
    "    end = wavelet_coefs.shape[1]\n",
    "    frames = []\n",
    "    frame_size = 4000\n",
    "    count = 0\n",
    "\n",
    "    while start + frame_size <= end -1:\n",
    "        f = (wavelet_coefs)[:, start:start+frame_size]\n",
    "        assert f.shape[1] == frame_size\n",
    "        frames.append(np.abs(f))\n",
    "        start += frame_size\n",
    "\n",
    "    frames = np.array(frames)\n",
    "    frames = frames.reshape((len(frames), frame_size, wavelet_coefs.shape[0]))\n",
    "    labels = np.ones(shape=(len(frames), 1))* int(label)\n",
    "\n",
    "    return frames, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[file, int(file.split('\\\\')[-1].split('-')[2])-1] for file in audio_files_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (1008,), labels: (1008,)\n",
      "Validation: (324,), labels: (324,)\n",
      "Testing: (108,), labels: (108,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_, y_train, y_ = train_test_split(data[:, 0], data[:, -1], test_size=0.3, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_, y_, test_size=0.25, random_state=42)\n",
    "labels = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']\n",
    "\n",
    "print(f\"Training: {x_train.shape}, labels: {y_train.shape}\")\n",
    "print(f\"Validation: {x_val.shape}, labels: {y_val.shape}\")\n",
    "print(f\"Testing: {x_test.shape}, labels: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='<U61'), array([ 71, 124, 137, 134, 136, 146, 130, 130], dtype=int64))\n",
      "(array(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='<U61'), array([18, 47, 42, 45, 41, 35, 45, 51], dtype=int64))\n",
      "(array(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='<U61'), array([ 7, 21, 13, 13, 15, 11, 17, 11], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_val, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "test = x_train[0]\n",
    "test_label = y_train[0]\n",
    "seq, sr = librosa.load(test, sr=16000)\n",
    "norm, noisy = preprocess_audio(seq)\n",
    "segs, label = compute_wavelet_features(norm, test_label)\n",
    "print(len(segs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 125, 4000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Label 0: 100%|██████████| 10/10 [00:19<00:00,  1.97s/it]\n",
      "Label 1: 100%|██████████| 10/10 [00:24<00:00,  2.43s/it]\n",
      "Label 2: 100%|██████████| 10/10 [00:24<00:00,  2.45s/it]\n",
      "Label 3: 100%|██████████| 10/10 [00:31<00:00,  3.12s/it]\n",
      "Label 4: 100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
      "Label 5: 100%|██████████| 10/10 [00:38<00:00,  3.83s/it]\n",
      "Label 6: 100%|██████████| 10/10 [00:44<00:00,  4.47s/it]\n",
      "Label 7: 100%|██████████| 10/10 [00:50<00:00,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (1510, 125, 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set a seed for reproducibility\n",
    "seed(42)\n",
    "\n",
    "# Initialize lists to store data\n",
    "x_train_wavelet = []\n",
    "y_train_wavelet = []\n",
    "uniq_id = []\n",
    "\n",
    "# Iterate over individual labels\n",
    "count = 0\n",
    "num_rand_samp = 10\n",
    "\n",
    "for label_index in range(len(labels)):\n",
    "    label_indices = np.where(y_train == str(label_index))[0]\n",
    "    selected_indices = sample(label_indices.tolist(), min(num_rand_samp, len(label_indices)))\n",
    "\n",
    "    for audio_index in tqdm(selected_indices, desc=f\"Label {label_index}\"):\n",
    "        current_sample = x_train[audio_index]\n",
    "        seq, _ = librosa.load(current_sample, sr=16000)\n",
    "        normalised_audio, noisy_audio = preprocess_audio(audio=seq)\n",
    "\n",
    "        for audio_type, audio_data in enumerate([normalised_audio, noisy_audio]):\n",
    "            features, labelss = compute_wavelet_features(audio=audio_data, label=label_index)\n",
    "\n",
    "            # Randomly sample from features\n",
    "            indices = np.arange(len(features))\n",
    "            selected_indices = sample(indices.tolist(), min(num_rand_samp, len(indices)))\n",
    "            selected_features = features[selected_indices]\n",
    "\n",
    "            # Update lists\n",
    "            uniq_id += [count] * len(selected_features)\n",
    "            y_train_wavelet.extend(y_train[audio_index])\n",
    "\n",
    "            if count == 0:\n",
    "                x_train_wavelet = selected_features\n",
    "            else:\n",
    "                x_train_wavelet = np.concatenate((x_train_wavelet, selected_features), axis=0)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "print(f\"X: {x_train_wavelet.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1510, 125, 4000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_wavelet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_wavelet = np.array(y_train_wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='<U1'),\n",
       " array([20, 20, 20, 20, 20, 20, 20, 20], dtype=int64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_wavelet, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving training data locally\n",
    "x_train_wavelet = []\n",
    "y_train_wavelet = []\n",
    "\n",
    "for i in range(len(labels)): #iterate over individual labels\n",
    "    ind, = np.where(y_train == str(i))\n",
    "    seed(i)\n",
    "    ind = ind.tolist()\n",
    "\n",
    "    for j in tqdm(range(len(x_train))):\n",
    "        current_sample = x_train[j]\n",
    "        seq, _ = librosa.load(current_sample, sr=16000)\n",
    "        normalised_audio, noisy_audio = preprocess_audio(audio=seq)\n",
    "        for i in range(2):\n",
    "            if i == 0:\n",
    "                F = compute_wavelet_features(audio=normalised_audio)\n",
    "                F = F.astype(np.float16)\n",
    "            else:\n",
    "                F = compute_wavelet_features(audio=noisy_audio)\n",
    "                F = F.astype(np.float16)\n",
    "            \n",
    "            y_train_wavelet.append(i)\n",
    "            x_train_wavelet.append(F)\n",
    "            \n",
    "\n",
    "x_train_wavelet = np.array(x_train_wavelet)\n",
    "print(f\"X: {x_train_wavelet.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:14<00:00,  2.68s/it]\n",
      "100%|██████████| 50/50 [02:44<00:00,  3.29s/it]\n",
      "100%|██████████| 50/50 [02:36<00:00,  3.13s/it]\n",
      "100%|██████████| 50/50 [03:03<00:00,  3.68s/it]\n",
      "100%|██████████| 50/50 [03:11<00:00,  3.83s/it]\n",
      "100%|██████████| 50/50 [03:38<00:00,  4.38s/it]\n",
      "100%|██████████| 50/50 [04:08<00:00,  4.97s/it]\n",
      "100%|██████████| 50/50 [03:56<00:00,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (40000, 157, 400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# saving training data locally\n",
    "indices = []\n",
    "x_train_wavelet = []\n",
    "y_train_wavelet = []\n",
    "uniq_id = []\n",
    "count = 0\n",
    "\n",
    "for i in range(len(labels)): #iterate over individual labels\n",
    "    ind, = np.where(y_train == str(i))\n",
    "    seed(i)\n",
    "    ind = ind.tolist()\n",
    "    ind = sample(ind, 50)\n",
    "    audio_samples = x_train[ind]\n",
    "    num_rand_samp = 50\n",
    "\n",
    "    for j in tqdm(range(len(audio_samples))):\n",
    "        current_sample = audio_samples[j]\n",
    "        seq, _ = librosa.load(current_sample, sr=16000)\n",
    "        normalised_audio, noisy_audio = preprocess_audio(audio=seq)\n",
    "        for i in range(2):\n",
    "            if i == 0:\n",
    "                F = compute_wavelet_features(audio=normalised_audio)\n",
    "                F = F.astype(np.float16)\n",
    "            else:\n",
    "                F = compute_wavelet_features(audio=noisy_audio)\n",
    "                F = F.astype(np.float16)\n",
    "            \n",
    "            indices = np.arange(0, len(F), 1)\n",
    "            indices = indices.tolist()\n",
    "            indices = sample(indices, min(num_rand_samp, len(indices)))\n",
    "            F = F[indices]\n",
    "            uniq_id += [count] * len(F)\n",
    "            y_train_wavelet.append(i)\n",
    "\n",
    "            if count == 0 :\n",
    "                x_train_wavelet = F\n",
    "            else :\n",
    "                x_train_wavelet = np.concatenate((x_train_wavelet, F), axis=0) \n",
    "            \n",
    "            count += 1\n",
    "\n",
    "print(f\"X: {x_train_wavelet.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_wavelet = np.array(x_train_wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 157, 400)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_wavelet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:  (800,)  unique:  (array([0, 1]), array([400, 400], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "y_train_wavelet = np.array(y_train_wavelet)\n",
    "print(\"Y: \", y_train_wavelet.shape, \" unique: \", np.unique(y_train_wavelet, return_counts=True))\n",
    "# Write all features to a .npz file\n",
    "np.savez_compressed(os.getcwd()+\"/training_features\", a=x_train_wavelet, b=y_train_wavelet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving training data locally\n",
    "x_val_wavelet = []\n",
    "y_val_wavelet = []\n",
    "\n",
    "for i in range(len(labels)): #iterate over individual labels\n",
    "    ind, = np.where(y_val == str(i))\n",
    "    seed(i)\n",
    "    ind = ind.tolist()\n",
    "\n",
    "    for j in tqdm(range(len(x_val))):\n",
    "        current_sample = x_val[j]\n",
    "        seq, _ = librosa.load(current_sample, sr=16000)\n",
    "        normalised_audio, noisy_audio = preprocess_audio(audio=seq)\n",
    "        for i in range(2):\n",
    "            if i == 0:\n",
    "                F = compute_wavelet_features(audio=normalised_audio)\n",
    "                F = F.astype(np.float16)\n",
    "            else:\n",
    "                F = compute_wavelet_features(audio=noisy_audio)\n",
    "                F = F.astype(np.float16)\n",
    "            \n",
    "            y_val_wavelet.append(i)\n",
    "            x_val_wavelet.append(F)\n",
    "            \n",
    "x_val_wavelet = np.array(x_val_wavelet)\n",
    "print(f\"X: {x_val_wavelet.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_wavelet = np.array(y_val_wavelet)\n",
    "print(\"Y: \", y_val_wavelet.shape, \" unique: \", np.unique(y_val_wavelet, return_counts=True))\n",
    "# Write all features to a .npz file\n",
    "np.savez_compressed(os.getcwd()+\"/val_features\", a=x_val_wavelet, b=y_val_wavelet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving training data locally\n",
    "x_test_wavelet = []\n",
    "y_test_wavelet = []\n",
    "\n",
    "for i in range(len(labels)): #iterate over individual labels\n",
    "    ind, = np.where(y_test == str(i))\n",
    "    seed(i)\n",
    "    ind = ind.tolist()\n",
    "\n",
    "    for j in tqdm(range(len(x_test))):\n",
    "        current_sample = x_test[j]\n",
    "        seq, _ = librosa.load(current_sample, sr=16000)\n",
    "        normalised_audio, noisy_audio = preprocess_audio(audio=seq)\n",
    "        for i in range(2):\n",
    "            if i == 0:\n",
    "                F = compute_wavelet_features(audio=normalised_audio)\n",
    "                F = F.astype(np.float16)\n",
    "            else:\n",
    "                F = compute_wavelet_features(audio=noisy_audio)\n",
    "                F = F.astype(np.float16)\n",
    "            \n",
    "            y_test_wavelet.append(i)\n",
    "            x_test_wavelet.append(F)\n",
    "            \n",
    "x_test_wavelet = np.array(x_test_wavelet)\n",
    "print(f\"X: {x_test_wavelet.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_wavelet = np.array(y_test_wavelet)\n",
    "print(\"Y: \", y_test_wavelet.shape, \" unique: \", np.unique(y_test_wavelet, return_counts=True))\n",
    "# Write all features to a .npz file\n",
    "np.savez_compressed(os.getcwd()+\"/test_features\", a=x_test_wavelet, b=y_test_wavelet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2eeecace2be6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0maudio_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mnum_rand_samp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vijay\\miniconda3\\envs\\tf\\lib\\random.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, population, k)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m21\u001b[0m        \u001b[1;31m# size of a small set minus size of an empty list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "indices = []\n",
    "x_val_wavelet = []\n",
    "y_val_wavelet = []\n",
    "uniq_id = []\n",
    "count = 0\n",
    "\n",
    "for i in range(len(labels)): #iterate over individual labels\n",
    "    ind, = np.where(y_val == str(i))\n",
    "    seed(i)\n",
    "    ind = ind.tolist()\n",
    "    ind = sample(ind, 50)\n",
    "    audio_samples = x_val[ind]\n",
    "    num_rand_samp = 50\n",
    "\n",
    "    for j in tqdm(range(len(audio_samples))):\n",
    "        current_sample = audio_samples[j]\n",
    "        seq, _ = librosa.load(current_sample, sr=16000)\n",
    "        normalised_audio, noisy_audio = preprocess_audio(audio=seq)\n",
    "        for i in range(2):\n",
    "            if i == 0:\n",
    "                F = compute_wavelet_features(audio=normalised_audio)\n",
    "                F = F.astype(np.float16)\n",
    "            else:\n",
    "                F = compute_wavelet_features(audio=noisy_audio)\n",
    "                F = F.astype(np.float16)\n",
    "            \n",
    "            indices = np.arange(0, len(F), 1)\n",
    "            indices = indices.tolist()\n",
    "            indices = sample(indices, min(num_rand_samp, len(indices)))\n",
    "            F = F[indices]\n",
    "            uniq_id += [count] * len(F)\n",
    "            y_val_wavelet.append(i)\n",
    "\n",
    "            if count == 0 :\n",
    "                x_val_wavelet = F\n",
    "            else :\n",
    "                x_val_wavelet = np.concatenate((x_val_wavelet, F), axis=0) \n",
    "            \n",
    "            count += 1\n",
    "\n",
    "print(f\"X: {x_val_wavelet.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all features to a .npz file\n",
    "np.savez_compressed(os.getcwd()+\"/validation_features\", a=x_val_wavelet, b=y_val_wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_wavelet = [] # Store wavelet features. We have each sample into frames of length 400\n",
    "y_val_wavelet = [] # Store class labels corresponding to wavelet features from an audio sample\n",
    "uniq_id = []\n",
    "\n",
    "for i in tqdm(range(len(x_val))) :\n",
    "\n",
    "    curr_sample = x_val[i]\n",
    "    seq, _ = librosa.load(curr_sample) \n",
    "    curr_target = y_val[i]\n",
    "    F = compute_wavelet_features(seq)\n",
    "\n",
    "    # Generate target labels corresponding to the frames of each sample\n",
    "    y_val_wavelet += [curr_target] * len(F)\n",
    "    uniq_id += [i] * len(F)\n",
    "\n",
    "    if i == 0 :\n",
    "        x_val_wavelet = F\n",
    "    else :\n",
    "        x_val_wavelet = np.concatenate((x_val_wavelet, F), axis=0) \n",
    "\n",
    "y_val_wavelet = np.array(y_val_wavelet) # Convert to numpy array\n",
    "uniq_id = np.array(uniq_id)\n",
    "print(\"X: \", x_val_wavelet.shape, \"  y: \", y_val_wavelet.shape)\n",
    "\n",
    "x_val_wavelet = x_val_wavelet.astype(np.float16)\n",
    "\n",
    "# Write all features to a .npz file\n",
    "np.savez_compressed(os.getcwd()+\"/validation_features\", a=x_val_wavelet, b=y_val_wavelet, c=uniq_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "x_test_wavelet = []\n",
    "y_test_wavelet = []\n",
    "uniq_id = []\n",
    "count = 0\n",
    "\n",
    "for i in range(len(labels)): #iterate over individual labels\n",
    "    ind, = np.where(y_test == str(i))\n",
    "    seed(i)\n",
    "    ind = ind.tolist()\n",
    "    ind = sample(ind, 50)\n",
    "    audio_samples = x_test[ind]\n",
    "    num_rand_samp = 50\n",
    "\n",
    "    for j in tqdm(range(len(audio_samples))):\n",
    "        current_sample = audio_samples[j]\n",
    "        seq, _ = librosa.load(current_sample, sr=16000)\n",
    "        normalised_audio, noisy_audio = preprocess_audio(audio=seq)\n",
    "        for i in range(2):\n",
    "            if i == 0:\n",
    "                F = compute_wavelet_features(audio=normalised_audio)\n",
    "                F = F.astype(np.float16)\n",
    "            else:\n",
    "                F = compute_wavelet_features(audio=noisy_audio)\n",
    "                F = F.astype(np.float16)\n",
    "            \n",
    "            indices = np.arange(0, len(F), 1)\n",
    "            indices = indices.tolist()\n",
    "            indices = sample(indices, min(num_rand_samp, len(indices)))\n",
    "            F = F[indices]\n",
    "            uniq_id += [count] * len(F)\n",
    "            y_test_wavelet.append(i)\n",
    "\n",
    "            if count == 0 :\n",
    "                x_test_wavelet = F\n",
    "            else :\n",
    "                x_test_wavelet = np.concatenate((x_test_wavelet, F), axis=0) \n",
    "            \n",
    "            count += 1\n",
    "\n",
    "print(f\"X: {x_test_wavelet.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(os.getcwd()+\"/testing_features\", a=x_test_wavelet, b=y_test_wavelet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"x_test_wavelet = [] # Store wavelet features. We have each sample into frames of length 400\n",
    "y_test_wavelet = [] # Store class labels corresponding to wavelet features from an audio sample\n",
    "uniq_id = []\n",
    "\n",
    "for i in tqdm(range(len(x_test))) :\n",
    "\n",
    "    curr_sample = x_test[i]\n",
    "    seq, _ = librosa.load(curr_sample) \n",
    "    curr_target = y_test[i]\n",
    "    F = compute_wavelet_features(seq)\n",
    "\n",
    "    # Generate target labels corresponding to the frames of each sample\n",
    "    y_test_wavelet += [curr_target] * len(F)\n",
    "    uniq_id += [i] * len(F)\n",
    "\n",
    "    if i == 0 :\n",
    "        x_test_wavelet = F\n",
    "    else :\n",
    "        x_test_wavelet = np.concatenate((x_test_wavelet, F), axis=0) \n",
    "\n",
    "y_test_wavelet = np.array(y_test_wavelet) # Convert to numpy array\n",
    "uniq_id = np.array(uniq_id)\n",
    "print(\"X: \", x_test_wavelet.shape, \"  y: \", y_test_wavelet.shape)\n",
    "\n",
    "x_test_wavelet = x_test_wavelet.astype(np.float16)\n",
    "\n",
    "# Write all features to a .npz file\n",
    "np.savez_compressed(os.getcwd()+\"/testing_features\", a=x_test_wavelet, b=y_test_wavelet, c=uniq_id)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./training_features.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 157, 400)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['a'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([400, 400], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['b'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
