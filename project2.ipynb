{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pywt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "from random import seed, random, randint, sample\n",
    "from scipy.signal import hilbert, chirp\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "from scipy.interpolate import interp2d\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440 Audio files fetched...\n",
      "\n",
      "neutral -> 96 samples.\n",
      "calm -> 192 samples.\n",
      "happy -> 192 samples.\n",
      "sad -> 192 samples.\n",
      "angry -> 192 samples.\n",
      "fearful -> 192 samples.\n",
      "disgust -> 192 samples.\n",
      "surprised -> 192 samples.\n"
     ]
    }
   ],
   "source": [
    "# using speech data\n",
    "speech_folder_name = './Audio_Speech_Actors_01-24/'\n",
    "actors_folder_name = [os.path.join(speech_folder_name, actor) for actor in os.listdir(speech_folder_name)]\n",
    "audio_files_path = [os.path.join(actor_num, file) for actor_num in actors_folder_name for file in os.listdir(actor_num)]\n",
    "data = np.array([[file_path, int(file_path.split('\\\\')[-1].split('-')[2])-1] for file_path in audio_files_path])\n",
    "\n",
    "labels = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']\n",
    "print(f\"{len(audio_files_path)} Audio files fetched...\\n\")\n",
    "labels_idx, count = np.unique(data[:, -1], return_counts=True)\n",
    "for i in range(len(count)):\n",
    "    print(f\"{labels[int(labels_idx[i])]} -> {count[i]} samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_awgn(audio):\n",
    "    snr_db = np.random.uniform(15, 30)\n",
    "    noise_std = np.sqrt(np.var(audio) / (10 ** (snr_db / 10)))\n",
    "    gaussian_noise = np.random.normal(0, noise_std, len(audio))\n",
    "    return audio + gaussian_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(audio):\n",
    "    trimmed, idx = librosa.effects.trim(audio)\n",
    "    norm_seq = (trimmed - np.mean(trimmed)) / np.std(trimmed)\n",
    "    noisy = add_awgn(norm_seq)\n",
    "\n",
    "    return norm_seq, noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wavelet_features(audio, label):\n",
    "    wavelet = 'morl'\n",
    "    sr = 16000\n",
    "    widths = np.arange(1, 256)\n",
    "    #print(f\"Scales using: {widths}\")\n",
    "\n",
    "    dt = 1/sr\n",
    "    frequencies = pywt.scale2frequency(wavelet=wavelet, scale=widths) / dt\n",
    "    #print(f\"Frequencies associated with the scales: {frequencies}\")\n",
    "\n",
    "    #creating filter to select frequencies between 20Hz and 5Khz - this is where most speech lies\n",
    "    upper = [x for x in range(len(widths)) if frequencies[x] > 2000][-1]\n",
    "    lower = [x for x in range(len(widths)) if frequencies[x] < 100][0]\n",
    "\n",
    "    widths = widths[upper:lower]\n",
    "\n",
    "    #computing wavelet transform \n",
    "    wavelet_coefs, freqs = pywt.cwt(audio, widths, wavelet=wavelet, sampling_period=dt)\n",
    "    #print(f\"shape of wavelet transform: {wavelet_coefs.shape}\")\n",
    "\n",
    "    # Fixed Segment Generation\n",
    "    start = 0\n",
    "    end = wavelet_coefs.shape[1]\n",
    "    frames = []\n",
    "    frame_size = 4000\n",
    "    count = 0\n",
    "\n",
    "    while start + frame_size <= end -1:\n",
    "        f = (wavelet_coefs)[:, start:start+frame_size]\n",
    "        assert f.shape[1] == frame_size\n",
    "        frames.append(f)\n",
    "        start += frame_size\n",
    "\n",
    "    frames = np.array(frames)\n",
    "    frames = frames.reshape((len(frames), frame_size, wavelet_coefs.shape[0]))\n",
    "    labels = np.ones(shape=(len(frames), 1))* int(label)\n",
    "\n",
    "    return frames, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = np.array([[file, int(file.split('\\\\')[-1].split('-')[2])-1] for file in audio_files_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (42,), labels: (42,)\n",
      "Validation: (13,), labels: (13,)\n",
      "Testing: (5,), labels: (5,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_, y_train, y_ = train_test_split(data[:60, 0], data[:60, -1], test_size=0.3, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_, y_, test_size=0.25, random_state=42)\n",
    "labels = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']\n",
    "\n",
    "print(f\"Training: {x_train.shape}, labels: {y_train.shape}\")\n",
    "print(f\"Validation: {x_val.shape}, labels: {y_val.shape}\")\n",
    "print(f\"Testing: {x_test.shape}, labels: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='<U61'), array([2, 5, 5, 8, 6, 7, 4, 5], dtype=int64))\n",
      "(array(['0', '1', '2', '4', '5', '6', '7'], dtype='<U61'), array([1, 2, 2, 2, 1, 3, 2], dtype=int64))\n",
      "(array(['0', '1', '2', '6', '7'], dtype='<U61'), array([1, 1, 1, 1, 1], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_val, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Label 0: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]\n",
      "Label 1: 100%|██████████| 5/5 [00:10<00:00,  2.08s/it]\n",
      "Label 2: 100%|██████████| 5/5 [00:10<00:00,  2.00s/it]\n",
      "Label 3: 100%|██████████| 8/8 [00:19<00:00,  2.39s/it]\n",
      "Label 4: 100%|██████████| 6/6 [00:19<00:00,  3.32s/it]\n",
      "Label 5: 100%|██████████| 7/7 [00:30<00:00,  4.34s/it]\n",
      "Label 6: 100%|██████████| 4/4 [00:17<00:00,  4.33s/it]\n",
      "Label 7: 100%|██████████| 5/5 [00:18<00:00,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (930, 4000, 125)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training data saving\n",
    "# Set a seed for reproducibility\n",
    "seed(42)\n",
    "\n",
    "# Initialize lists to store data\n",
    "x_train_wavelet = []\n",
    "y_train_wavelet = []\n",
    "uniq_id = []\n",
    "\n",
    "# Iterate over individual labels\n",
    "count = 0\n",
    "num_rand_samp = 100\n",
    "\n",
    "for label_index in range(len(labels)):\n",
    "    label_indices = np.where(y_train == str(label_index))[0]\n",
    "    selected_indices = sample(label_indices.tolist(), min(num_rand_samp, len(label_indices)))\n",
    "\n",
    "    for audio_index in tqdm(selected_indices, desc=f\"Label {label_index}\"):\n",
    "        current_sample = x_train[audio_index]\n",
    "        seq, _ = librosa.load(current_sample, sr=16000)\n",
    "        normalised_audio, noisy_audio = preprocess_audio(audio=seq)\n",
    "\n",
    "        for audio_type, audio_data in enumerate([normalised_audio, noisy_audio]):\n",
    "            features, labelss = compute_wavelet_features(audio=audio_data, label=label_index)\n",
    "\n",
    "            # Randomly sample from features\n",
    "            indices = np.arange(len(features))\n",
    "            selected_indices = sample(indices.tolist(), min(num_rand_samp, len(indices)))\n",
    "            selected_features = features[selected_indices]\n",
    "\n",
    "            # Update lists\n",
    "            uniq_id += [count] * len(selected_features)\n",
    "            y_train_wavelet.extend(labelss)\n",
    "\n",
    "            if count == 0:\n",
    "                x_train_wavelet = selected_features\n",
    "            else:\n",
    "                x_train_wavelet = np.concatenate((x_train_wavelet, selected_features), axis=0)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "print(f\"X: {x_train_wavelet.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:  (930, 1)  unique:  (array([0., 1., 2., 3., 4., 5., 6., 7.]), array([ 34, 128, 104, 164, 138, 200,  94,  68], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "y_train_wavelet = np.array(y_train_wavelet)\n",
    "print(\"Y: \", y_train_wavelet.shape, \" unique: \", np.unique(y_train_wavelet, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all features to a .npz file\n",
    "np.savez_compressed(os.getcwd()+\"/training_features\", a=x_train_wavelet, b=y_train_wavelet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Data saving..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Label 0: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "Label 1: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]\n",
      "Label 2: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]\n",
      "Label 3: 0it [00:00, ?it/s]\n",
      "Label 4: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]\n",
      "Label 5: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "Label 6: 100%|██████████| 3/3 [00:07<00:00,  2.57s/it]\n",
      "Label 7: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (264, 4000, 125)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# validation data saving\n",
    "# Set a seed for reproducibility\n",
    "seed(42)\n",
    "\n",
    "# Initialize lists to store data\n",
    "x_val_wavelet = []\n",
    "y_val_wavelet = []\n",
    "uniq_id = []\n",
    "\n",
    "# Iterate over individual labels\n",
    "count = 0\n",
    "num_rand_samp = 100\n",
    "\n",
    "for label_index in range(len(labels)):\n",
    "    label_indices = np.where(y_val == str(label_index))[0]\n",
    "    selected_indices = sample(label_indices.tolist(), min(num_rand_samp, len(label_indices)))\n",
    "\n",
    "    for audio_index in tqdm(selected_indices, desc=f\"Label {label_index}\"):\n",
    "        current_sample = x_val[audio_index]\n",
    "        seq, _ = librosa.load(current_sample, sr=16000)\n",
    "        normalised_audio, noisy_audio = preprocess_audio(audio=seq)\n",
    "\n",
    "        for audio_type, audio_data in enumerate([normalised_audio, noisy_audio]):\n",
    "            features, labelss = compute_wavelet_features(audio=audio_data, label=label_index)\n",
    "\n",
    "            # Randomly sample from features\n",
    "            indices = np.arange(len(features))\n",
    "            selected_indices = sample(indices.tolist(), min(num_rand_samp, len(indices)))\n",
    "            selected_features = features[selected_indices]\n",
    "\n",
    "            # Update lists\n",
    "            uniq_id += [count] * len(selected_features)\n",
    "            y_val_wavelet.extend(labelss)\n",
    "\n",
    "            if count == 0:\n",
    "                x_val_wavelet = selected_features\n",
    "            else:\n",
    "                x_val_wavelet = np.concatenate((x_val_wavelet, selected_features), axis=0)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "print(f\"X: {x_val_wavelet.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:  (264, 1)  unique:  (array([0., 1., 2., 4., 5., 6., 7.]), array([12, 46, 38, 44, 22, 74, 28], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "y_val_wavelet = np.array(y_val_wavelet)\n",
    "print(\"Y: \", y_val_wavelet.shape, \" unique: \", np.unique(y_val_wavelet, return_counts=True))\n",
    "# Write all features to a .npz file\n",
    "np.savez_compressed(os.getcwd()+\"/validation_features\", a=x_val_wavelet, b=y_val_wavelet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing data saving..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Label 0: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Label 1: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "Label 2: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "Label 3: 0it [00:00, ?it/s]\n",
      "Label 4: 0it [00:00, ?it/s]\n",
      "Label 5: 0it [00:00, ?it/s]\n",
      "Label 6: 100%|██████████| 1/1 [00:01<00:00,  1.94s/it]\n",
      "Label 7: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (84, 4000, 125)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# validation data saving\n",
    "# Set a seed for reproducibility\n",
    "seed(42)\n",
    "\n",
    "# Initialize lists to store data\n",
    "x_test_wavelet = []\n",
    "y_test_wavelet = []\n",
    "uniq_id = []\n",
    "\n",
    "# Iterate over individual labels\n",
    "count = 0\n",
    "num_rand_samp = 100\n",
    "\n",
    "for label_index in range(len(labels)):\n",
    "    label_indices = np.where(y_test == str(label_index))[0]\n",
    "    selected_indices = sample(label_indices.tolist(), min(num_rand_samp, len(label_indices)))\n",
    "\n",
    "    for audio_index in tqdm(selected_indices, desc=f\"Label {label_index}\"):\n",
    "        current_sample = x_test[audio_index]\n",
    "        seq, _ = librosa.load(current_sample, sr=16000)\n",
    "        normalised_audio, noisy_audio = preprocess_audio(audio=seq)\n",
    "\n",
    "        for audio_type, audio_data in enumerate([normalised_audio, noisy_audio]):\n",
    "            features, labelss = compute_wavelet_features(audio=audio_data, label=label_index)\n",
    "\n",
    "            # Randomly sample from features\n",
    "            indices = np.arange(len(features))\n",
    "            selected_indices = sample(indices.tolist(), min(num_rand_samp, len(indices)))\n",
    "            selected_features = features[selected_indices]\n",
    "\n",
    "            # Update lists\n",
    "            uniq_id += [count] * len(selected_features)\n",
    "            y_test_wavelet.extend(labelss)\n",
    "\n",
    "            if count == 0:\n",
    "                x_test_wavelet = selected_features\n",
    "            else:\n",
    "                x_test_wavelet = np.concatenate((x_test_wavelet, selected_features), axis=0)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "print(f\"X: {x_test_wavelet.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:  (84, 1)  unique:  (array([0., 1., 2., 6., 7.]), array([16, 16, 16, 22, 14], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "y_test_wavelet = np.array(y_test_wavelet)\n",
    "print(\"Y: \", y_test_wavelet.shape, \" unique: \", np.unique(y_test_wavelet, return_counts=True))\n",
    "# Write all features to a .npz file\n",
    "np.savez_compressed(os.getcwd()+\"/testing_features\", a=x_test_wavelet, b=y_test_wavelet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
